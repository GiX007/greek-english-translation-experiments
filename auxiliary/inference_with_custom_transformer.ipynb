{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Inference and qualitative evaluation on custom sentences or dataset samples.\n",
        "The process demonstrates how to run translation using the best saved checkpoint from a trained from-scratch Transformer."
      ],
      "metadata": {
        "id": "JF3bIwnC5HOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchmetrics"
      ],
      "metadata": {
        "id": "NAEitJmv62k7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w3QZuBoppB0t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchmetrics\n",
        "from config import get_config\n",
        "from utils import get_model\n",
        "from train import get_ds, run_validation\n",
        "from translate import translate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "config = get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qow6M2tl5gV6",
        "outputId": "09b60d87-31b7-4e7b-888c-d0604e2ebb20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtCqdsPc7O4m",
        "outputId": "e20308c8-1a8d-4c5e-cb8b-82df8e65d6c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
        "\n",
        "checkpoint_path = \"results/transformer_weights/tmodel__best.pt\"\n",
        "# checkpoint_path = \"/content/tmodel__best.pt\"\n",
        "checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=True)\n",
        "\n",
        "model.load_state_dict(checkpoint[\"model_weights\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TqSb4l57OY2",
        "outputId": "35ee85f8-991f-48d9-df6a-7603c00f7f85"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "run_validation(model, val_dataloader, tokenizer_tgt, config[\"seq_len\"], device, lambda msg: print(msg), global_step=0, writer=None, num_examples=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwl3P3f65gSw",
        "outputId": "f9f03075-62ec-4ce2-eb5e-e904bcd68a2c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "    SOURCE: Ο Αγαθούλης, η Κυνεγόνδη κ' η γριά ήσαν τώρα στη μικρή πόλη Αβασένα, ανάμεσα στα βουνά της Σιέρρα Μορένα και μιλούσαν ως εξής μέσα σε μια ταβέρνα.\n",
            "    TARGET: Candide, Cunegund, and the old woman, had by this time reached the little town of Avacena, in the midst of the mountains of Sierra Morena, and were engaged in the following conversation in an inn, where they had taken up their quarters.\n",
            " PREDICTED: Candide , who had been by the old woman , had been by the of , and , were so , where they had been so ugly , in the old woman had been brought by a manner of their quarters .\n",
            "----------------------------------------\n",
            "    SOURCE: Αυτός ο γιατρός ήτανε ο πιο άσχημος απ' όλους τους άντρες κ' εγώ η πιο δυστυχισμένη απ' όλα τα πλάσματα, αφού έτρωγα ξύλο για έναν άντρα, που δεν τον αγαπούσα.\n",
            "    TARGET: The doctor himself was the most ugly of all mortals, and I the most wretched creature existing, to be continually beaten for a man whom I did not love.\n",
            " PREDICTED: \" I am very good man for a great affection for the world , and it is an old man for a man who has very man for me to be more for them in the most dreadful man .\n",
            "----------------------------------------\n",
            "    SOURCE: Αλλού οι μισοί κάτοικοι είναι τρελοί, αλλού πολύ πονηροί, αλλού πολύ μαλακοί και πολύ κουτοί· αλλού κάνουνε πνεύμα· και παντού η πρώτη απασχόληση είναι ο έρωτας· η δεύτερη να κακολογούνε κ' η τρίτη να λένε ανοησίες. — Αλλά κύριε Μαρτίνε, έχετε ιδεί το Παρίσι;\n",
            "    TARGET: In some, one half of the people are fools and madmen; in some, they are too artful; in others, again, they are, in general, either very good-natured or very brutal; while in others, they affect to be witty, and in all, their ruling passion is love, the next is slander, and the last is to talk nonsense.\"\n",
            " PREDICTED: \" I have heard ,\" said Candide , \" to Martin , as they are a of that ; but , in this world is an auto - da - da - fe , or in the world , and in others , or not withstanding , or to the world , they are , or to the world ; they are not withstanding , or the world , or not withstanding , they are not in this world , or in this world , and in others to the world is a man .\"\n",
            "----------------------------------------\n",
            "    SOURCE: Δεν ξέρανε, αν αυτές οι φωνές ήτανε χαράς ή πόνου· όμως πεταχτήκανε ορμητικά επάνω με την ανησυχία και τον τρόμο, που εμπνέουν όλα σ' έναν τόπο άγνωστο.\n",
            "    TARGET: They could not tell whether these were cries of grief or of joy; however, they instantly started up, full of that inquietude and apprehension which a strange place naturally inspires.\n",
            " PREDICTED: I was a very , and in the of , but the same manner of , but the whole province of , who had been a , but did not been a .\n",
            "----------------------------------------\n",
            "    SOURCE: Τέλος τόνα από τα δυο καράβια έρριξε στο άλλο μια ομοβροντία τόσο χαμηλά και τόσο πετυχημένη που το βύθισε ολότελα.\n",
            "    TARGET: After several smart broadsides the one gave the other a shot between wind and water which sunk her outright.\n",
            " PREDICTED: The of the other , a of , which he took him from her his .\n",
            "----------------------------------------\n",
            "    SOURCE: Ένας κορδελιέρος, που ήτανε ο εξομολογητής μου, με πλάνεψε.\n",
            "    TARGET: A Franciscan, who was my confessor, easily seduced me; the consequences proved terrible.\n",
            " PREDICTED: I was at the of , and , who had been for ; but I was a for , and .\n",
            "----------------------------------------\n",
            "    SOURCE: Αυτά τα θεάματα διπλασιάσανε τις συζητήσεις κι' όσον δε συζητούσανε, η ανία ήτανε τόσο υπερβολική, που η γριά τόλμησε μια μέρα να τους πη: — Θάθελα να ξέρω τι ναι χειρότερο: νάχεις βιαστή εκατό φορές από νέγρους πειρατές, να σούχουν κόψει τόνα κωλομέρι, νάχης ξυλοκοπηθή από τους Βουλγάρους, νάχης μαστιγωθή και κρεμαστή σ' ένα άουτο- νταφέ, νάχης σκιστή με το μαχαίρι, νάχης τραβήξη κουπί σε γαλέρα, νάχης όλες τις δυστυχίες, που έχουμε μεις περάσει, ή να μένης δω, χωρίς να κάμνης τίποτα;\n",
            "    TARGET: Such sights gave occasion to frequent dissertations; and when no disputes were in progress, the irksomeness was so excessive that the old woman ventured one day to tell them: \"I would be glad to know which is worst, to be ravished a hundred times by Negro pirates, to have one buttock cut off, to run the gauntlet among the Bulgarians, to be whipped and hanged at an auto-da-fe, to be dissected, to be chained to an oar in a galley; and, in short, to experience all the miseries through which every one of us hath passed, or to remain here doing nothing?\"\n",
            " PREDICTED: \" I am very to see the people of a ,\" said Candide , \" that , who had taken up a it were so much as to say , I have been a prodigious number of being one hundred times , and yet when they are not withstanding , or rather than to to be ; and as I have been to to to to to the world .\n",
            "----------------------------------------\n",
            "    SOURCE: Δεν ξέρω με ποια ζυγαριά ο Παγγλώσσης σας μπορούσε να ζυγιάζη τα δυστυχήματα των ανθρώπων να εχτιμά τις λύπες τους.\n",
            "    TARGET: \"I know not,\" said Martin, \"in what balance your Pangloss could have weighed the misfortunes of mankind, and have set a just estimation on their sufferings.\n",
            " PREDICTED: \" I have not a great affection for ,\" said Martin , \" in this world you , and you have made a for for the of the in their country .\"\n",
            "----------------------------------------\n",
            "    SOURCE: Ήτανε περικυκλωμένοι από καμιά πενηνταριά Αυτιάδες ολόγυμνους, ωπλισμένους με βέλη, ρόπαλα και μπαλτάδες από πέτρα. Μερικοί βάζανε να βράσει ένα μεγάλο καζάνι' άλλοι ετοιμάζανε σούβλες κι' όλοι τους φωνάζανε: — Είναι Ιησουίτης! ένας Ιησουίτης!\n",
            "    TARGET: They saw themselves surrounded by fifty naked Oreillons armed with bows and arrows, clubs, and hatchets of flint; some were making a fire under a large cauldron; and others were preparing spits, crying out one and all, \"A Jesuit! a Jesuit! we shall be revenged; we shall have excellent cheer; let us eat this Jesuit; let us eat him up.\"\n",
            " PREDICTED: \" Alas !\" cried he , \" I have seen two , and you have made a Jesuit ! I am a Jesuit ! that for the King of the King of the , and yet I have been so much as I never seen and that everything is for the whole ; let us .\"\n",
            "----------------------------------------\n",
            "    SOURCE: Τίποτε δεν μπορεί να του αρέση.\n",
            "    TARGET: \"There would be no such great harm in that,\" said Martin.\n",
            " PREDICTED: \" Alas !\" said he , \" it is that it is a great deal of that it is .\"\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `CharErrorRate` from `torchmetrics` was deprecated and will be removed in 2.0. Import `CharErrorRate` from `torchmetrics.text` instead.\n",
            "  _future_warning(\n",
            "/usr/local/lib/python3.12/dist-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `WordErrorRate` from `torchmetrics` was deprecated and will be removed in 2.0. Import `WordErrorRate` from `torchmetrics.text` instead.\n",
            "  _future_warning(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07234422862529755"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from translate import translate"
      ],
      "metadata": {
        "id": "RUXlR-AgDXWX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"Πλήρωσε αμέσως τη ξαγορά του βαρώνου και του Παγγλώσση.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "x75BfqdN7jUu",
        "outputId": "43f97a8d-f2f3-42bb-b45d-484524678dc3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SOURCE:    Πλήρωσε αμέσως τη ξαγορά του βαρώνου και του Παγγλώσση.\n",
            "PREDICTED: Pangloss , by the Baron of Thunder - ten - tronckh , and he was in the Baron ' s body ; and I am more than to Pangloss .\n",
            "RAW OUTPUT IDS: [2, 63, 4, 47, 5, 132, 6, 451, 54, 221, 54, 475, 4, 8, 18, 15, 12, 5, 132, 50, 64, 304, 13, 8, 14, 87, 75, 82, 7, 63, 9, 3]\n",
            "Decoding time:     0.317 sec\n",
            "End-to-end time:   1.159 sec\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Pangloss , by the Baron of Thunder - ten - tronckh , and he was in the Baron ' s body ; and I am more than to Pangloss .\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "yXBIDBfb7lOF",
        "outputId": "ad5431fa-f6b9-42a0-87b4-247f7c58a625"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID:        42\n",
            "TARGET:    \"You are perfectly right, gentlemen,\" said Candide, \"this is precisely the doctrine of Master Pangloss; and I am convinced that everything is for the best.\"\n",
            "SOURCE:    — Έχετε δίκαιο, είπεν ο Αγαθούλης· αυτό μούλεγε πάντα ο κύριος Παγγλώσσης και παρατηρώ καλά, πως όλα είναι άριστα.\n",
            "PREDICTED: \" But , Reverend Father ,\" said Candide , \" this is the best of this world is true , for I am convinced that everything is for the best .\"\n",
            "RAW OUTPUT IDS: [2, 11, 117, 4, 346, 302, 25, 26, 19, 4, 11, 37, 22, 5, 151, 6, 37, 98, 22, 252, 4, 29, 14, 87, 1026, 16, 174, 22, 29, 5, 151, 23, 3]\n",
            "Decoding time:     0.305 sec\n",
            "End-to-end time:   1.899 sec\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\" But , Reverend Father ,\" said Candide , \" this is the best of this world is true , for I am convinced that everything is for the best .\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Simef0db7jQd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}